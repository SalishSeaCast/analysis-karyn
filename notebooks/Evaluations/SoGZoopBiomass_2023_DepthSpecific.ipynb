{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import model data for comparison with observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import subprocess\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import dateutil as dutil\n",
    "from salishsea_tools import viz_tools, places\n",
    "import xarray as xr\n",
    "from salishsea_tools import evaltools as et\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date = dt.datetime(2023,1,1)\n",
    "end_date = dt.datetime(2023,12,31)\n",
    "flen=1 # number of days per model output file. always 1 for 201905 and 201812 model runs\n",
    "namfmt='nowcast' # for 201905 and 201812 model runs, this should always be 'nowcast'\n",
    "# filemap is dictionary of the form variableName: fileType, where variableName is the name\n",
    "# of the variable you want to extract and fileType designates the type of \n",
    "# model output file it can be found in (usually ptrc_T for biology, grid_T for temperature and \n",
    "# salinity)\n",
    "filemap={'microzooplankton':'biol_T','mesozooplankton':'biol_T'}\n",
    "# fdict is a dictionary mappy file type to its time resolution. Here, 1 means hourly output\n",
    "# (1h file) and 24 means daily output (1d file). In certain runs, multiple time resolutions \n",
    "# are available\n",
    "fdict={'biol_T':24,'grid_T':24} #24 for hours averaged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'microzooplankton': 'biol_T', 'mesozooplankton': 'biol_T'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=nc.Dataset('/results2/SalishSea/nowcast-green.202111/26jul23/SalishSea_1d_20230726_20230726_biol_T.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nitrate', 'ammonium', 'silicon', 'diatoms', 'flagellates', 'microzooplankton', 'dissolved_organic_nitrogen', 'particulate_organic_nitrogen', 'biogenic_silicon', 'mesozooplankton', 'deptht', 'y', 'x', 'time_counter'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= '/results2/SalishSea/nowcast-green.202111/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('/ocean/ksuchy/MOAD/analysis-karyn/notebooks/Evaluations/2023_SoG_ZoopProd_DepthSpecific.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Date</th>\n",
       "      <th>Station</th>\n",
       "      <th>STN_TIME</th>\n",
       "      <th>Z_lower</th>\n",
       "      <th>Z_upper</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>BPR (mgC m-3 day-1)</th>\n",
       "      <th>daily P:B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-003</td>\n",
       "      <td>03/15/2023</td>\n",
       "      <td>Stn 42</td>\n",
       "      <td>12:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>49.016667</td>\n",
       "      <td>-123.433333</td>\n",
       "      <td>0.849489</td>\n",
       "      <td>0.067893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-003</td>\n",
       "      <td>03/15/2023</td>\n",
       "      <td>Stn 42</td>\n",
       "      <td>12:00</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>49.016667</td>\n",
       "      <td>-123.433333</td>\n",
       "      <td>3.473540</td>\n",
       "      <td>0.177075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-003</td>\n",
       "      <td>03/15/2023</td>\n",
       "      <td>Stn 42</td>\n",
       "      <td>12:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>49.016667</td>\n",
       "      <td>-123.433333</td>\n",
       "      <td>8.605914</td>\n",
       "      <td>0.474847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-003</td>\n",
       "      <td>03/15/2023</td>\n",
       "      <td>Stn 42</td>\n",
       "      <td>12:00</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49.016667</td>\n",
       "      <td>-123.433333</td>\n",
       "      <td>9.166827</td>\n",
       "      <td>0.382759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-003</td>\n",
       "      <td>03/15/2023</td>\n",
       "      <td>Stn 42</td>\n",
       "      <td>12:00</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>49.016667</td>\n",
       "      <td>-123.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2023-029</td>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>Stn 12</td>\n",
       "      <td>12:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>49.716667</td>\n",
       "      <td>-124.666667</td>\n",
       "      <td>0.096584</td>\n",
       "      <td>0.005107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2023-029</td>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>Stn 12</td>\n",
       "      <td>12:00</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49.716667</td>\n",
       "      <td>-124.666667</td>\n",
       "      <td>0.164719</td>\n",
       "      <td>0.006107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2023-029</td>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>Stn 12</td>\n",
       "      <td>12:00</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>49.716667</td>\n",
       "      <td>-124.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2023-029</td>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>Stn 12</td>\n",
       "      <td>12:00</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>49.716667</td>\n",
       "      <td>-124.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2023-029</td>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>Stn 12</td>\n",
       "      <td>12:00</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>49.716667</td>\n",
       "      <td>-124.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cruise        Date Station STN_TIME  Z_lower  Z_upper        Lat  \\\n",
       "0    2023-003  03/15/2023  Stn 42    12:00        5        5  49.016667   \n",
       "1    2023-003  03/15/2023  Stn 42    12:00       10       10  49.016667   \n",
       "2    2023-003  03/15/2023  Stn 42    12:00       20       20  49.016667   \n",
       "3    2023-003  03/15/2023  Stn 42    12:00       50       50  49.016667   \n",
       "4    2023-003  03/15/2023  Stn 42    12:00      150      150  49.016667   \n",
       "..        ...         ...     ...      ...      ...      ...        ...   \n",
       "168  2023-029  10/12/2023  Stn 12    12:00       20       20  49.716667   \n",
       "169  2023-029  10/12/2023  Stn 12    12:00       50       50  49.716667   \n",
       "170  2023-029  10/12/2023  Stn 12    12:00      150      150  49.716667   \n",
       "171  2023-029  10/12/2023  Stn 12    12:00      250      250  49.716667   \n",
       "172  2023-029  10/12/2023  Stn 12    12:00      350      350  49.716667   \n",
       "\n",
       "            Lon  BPR (mgC m-3 day-1)  daily P:B  \n",
       "0   -123.433333             0.849489   0.067893  \n",
       "1   -123.433333             3.473540   0.177075  \n",
       "2   -123.433333             8.605914   0.474847  \n",
       "3   -123.433333             9.166827   0.382759  \n",
       "4   -123.433333                  NaN        NaN  \n",
       "..          ...                  ...        ...  \n",
       "168 -124.666667             0.096584   0.005107  \n",
       "169 -124.666667             0.164719   0.006107  \n",
       "170 -124.666667                  NaN        NaN  \n",
       "171 -124.666667                  NaN        NaN  \n",
       "172 -124.666667                  NaN        NaN  \n",
       "\n",
       "[173 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'Date':'dtUTC'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date to proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('03/15/2023', '12:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['dtUTC'][0],df2['STN_TIME'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    03/15/2023\n",
       "1    03/15/2023\n",
       "2    03/15/2023\n",
       "3    03/15/2023\n",
       "4    03/15/2023\n",
       "5    03/15/2023\n",
       "6    03/16/2023\n",
       "7    03/16/2023\n",
       "8    03/16/2023\n",
       "9    03/16/2023\n",
       "Name: dtUTC, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['dtUTC'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03', '15', '2023']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['dtUTC'][0].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateslist=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in df2['dtUTC']:\n",
    "    dateslist.append(el.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslist=list()\n",
    "for el in df2['STN_TIME']:\n",
    "    timeslist.append(el.split(':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts=list()\n",
    "for ii,jj in zip(dateslist,timeslist):\n",
    "    dts.append(dt.datetime(int(ii[2]),int(ii[0]),int(ii[1]),int(jj[0]),int(jj[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      03/15/2023\n",
       "1      03/15/2023\n",
       "2      03/15/2023\n",
       "3      03/15/2023\n",
       "4      03/15/2023\n",
       "          ...    \n",
       "168    10/12/2023\n",
       "169    10/12/2023\n",
       "170    10/12/2023\n",
       "171    10/12/2023\n",
       "172    10/12/2023\n",
       "Name: dtUTC, Length: 173, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['dtUTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['dtUTC'] = df2['dtUTC'].apply(lambda x:\n",
    "    dt.datetime.strptime(x, '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['dtUTC']=[et.pac_to_utc(ii) for ii in df2['dtUTC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2023-03-15 07:00:00\n",
       "1     2023-03-15 07:00:00\n",
       "2     2023-03-15 07:00:00\n",
       "3     2023-03-15 07:00:00\n",
       "4     2023-03-15 07:00:00\n",
       "              ...        \n",
       "168   2023-10-12 07:00:00\n",
       "169   2023-10-12 07:00:00\n",
       "170   2023-10-12 07:00:00\n",
       "171   2023-10-12 07:00:00\n",
       "172   2023-10-12 07:00:00\n",
       "Name: dtUTC, Length: 173, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['dtUTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 07:00:00 biol_T 2007-01-01 12:00:00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time_centered_bounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/ocean/ksuchy/MOAD/tools/SalishSeaTools/salishsea_tools/evaltools.py:330\u001b[0m, in \u001b[0;36m_vertNetmatch\u001b[0;34m(data, flist, ftypes, filemap_r, gridmask, e3t0, maskName)\u001b[0m\n\u001b[1;32m    329\u001b[0m hpf\u001b[38;5;241m=\u001b[39m(flist[ift][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_n\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mflist[ift][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3600\u001b[39m \u001b[38;5;66;03m#hours per file\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m ih\u001b[38;5;241m=\u001b[39m\u001b[43m_getTimeInd_bin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdtUTC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mift\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mift\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhpf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhpf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflist[ift]\u001b[39m\u001b[38;5;124m'\u001b[39m,flist[ift][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/ocean/ksuchy/MOAD/tools/SalishSeaTools/salishsea_tools/evaltools.py:604\u001b[0m, in \u001b[0;36m_getTimeInd_bin\u001b[0;34m(idt, ifid, torig, hpf)\u001b[0m\n\u001b[1;32m    603\u001b[0m     tlist\u001b[38;5;241m=\u001b[39m[ii\u001b[38;5;241m+\u001b[39mhpf\u001b[38;5;241m/\u001b[39m(nt\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3600\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m ifid\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_counter\u001b[39m\u001b[38;5;124m'\u001b[39m][:]]\n\u001b[0;32m--> 604\u001b[0m     ih\u001b[38;5;241m=\u001b[39m\u001b[43m[\u001b[49m\u001b[43miii\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miii\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhhh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtlist\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhhh\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midt\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtorig\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_seconds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ih\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43met\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatchData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmeshPath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/sallen/MEOPAR/grid/mesh_mask202108.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvertNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m;\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/ocean/ksuchy/MOAD/tools/SalishSeaTools/salishsea_tools/evaltools.py:240\u001b[0m, in \u001b[0;36mmatchData\u001b[0;34m(data, filemap, fdict, mod_start, mod_end, mod_nam_fmt, mod_basedir, mod_flen, method, meshPath, maskName, wrapSearch, fastSearch, wrapTol, e3tvar, fid, sdim, quiet, preIndexed)\u001b[0m\n\u001b[1;32m    238\u001b[0m     data\u001b[38;5;241m=\u001b[39m _vvlBin(data,flist,ftypes,filemap,filemap_r,omask,fdict,e3tvar)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertNet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_vertNetmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflist\u001b[49m\u001b[43m,\u001b[49m\u001b[43mftypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilemap_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43momask\u001b[49m\u001b[43m,\u001b[49m\u001b[43me3t0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaskName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mmethod\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not written yet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/ocean/ksuchy/MOAD/tools/SalishSeaTools/salishsea_tools/evaltools.py:335\u001b[0m, in \u001b[0;36m_vertNetmatch\u001b[0;34m(data, flist, ftypes, filemap_r, gridmask, e3t0, maskName)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtUTC\u001b[39m\u001b[38;5;124m'\u001b[39m],ift,torig[ift])\n\u001b[0;32m--> 335\u001b[0m     tlist\u001b[38;5;241m=\u001b[39m\u001b[43mfid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mift\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_centered_bounds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:,:]\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m tlist:\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28mprint\u001b[39m(el)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_centered_bounds'"
     ]
    }
   ],
   "source": [
    "data = et.matchData(df2, filemap, fdict, start_date, end_date, namfmt, PATH, flen,\n",
    "                    meshPath='/home/sallen/MEOPAR/grid/mesh_mask202108.nc',\n",
    "                    quiet=False, method='vertNet');\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1=cmocean.cm.thermal\n",
    "with nc.Dataset('/ocean/ksuchy/MOAD/NEMO-forcing/grid/bathymetry_202108.nc') as bathy:\n",
    "    bathylon=np.copy(bathy.variables['nav_lon'][:,:])\n",
    "    bathylat=np.copy(bathy.variables['nav_lat'][:,:])\n",
    "    bathyZ=np.copy(bathy.variables['Bathymetry'][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mod_prod']=(data['mod_GRMESZDIAT']+data['mod_GRMESZPHY']+data['mod_GRMESZMICZ']+data['mod_GRMESZPON'])*86400*0.3*5.7*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['BPR (mgC m-3 day-1)'].min())\n",
    "print(data['BPR (mgC m-3 day-1)'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['mod_prod'].min())\n",
    "print(data['mod_prod'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byDepth(ax,obsvar,modvar,lims):\n",
    "    SI=et.varvarPlot(ax,data,obsvar,modvar,'Z_lower',(15,25),'z','m',('orange','darkturquoise','navy'))\n",
    "    l=ax.legend(handles=SI)\n",
    "    ax.set_xlabel('Log10 Observations (mg C m$^{-3}$ d$^{-1}$)+0.001')\n",
    "    ax.set_ylabel('Log10 Z2 Model (mg C m$^{-3}$ d$^{-1}$)+0.001')\n",
    "    ax.plot(lims,lims,'k-',alpha=.5)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect(1)\n",
    "    return SI,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(4,4))\n",
    "fig.subplots_adjust(hspace=1)\n",
    "ax.plot(data['BPR (mgC m-3 day-1)'],data['mod_prod'],'k.')\n",
    "ax.set_title('Mesozooplankton Productivity mg C m-3 d-1')\n",
    "ax.set_xlabel('Obs')\n",
    "ax.set_ylabel('Model')\n",
    "ax.plot((0,40),(0,40),'r-',alpha=.3)\n",
    "ax.set_xlim(0,40)\n",
    "ax.set_ylim(0,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvar='BPR (mgC m-3 day-1)'\n",
    "modvar='mod_prod'\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (4,4))\n",
    "SI,l=byDepth(ax,obsvar,modvar,(0,40))\n",
    "ax.set_title('Mesozooplankton Productivity mg C m-3 d-1 By Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define log transform function with slight shift to accommodate zero values\n",
    "def logt(x):\n",
    "    return np.log10(x+.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['L10Productivity']=logt(data['BPR (mgC m-3 day-1)'])\n",
    "data['L10mod_prod']=logt(data['mod_prod'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth-specific Point by Point comparisions of model vs obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvar2='L10Productivity'\n",
    "modvar2='L10mod_prod'\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (6,6))\n",
    "SI,l=byDepth(ax,obsvar2,modvar2,(-3,3))\n",
    "ax.set_title('Z2 Productivity (mg C m$^{-3}$ d$^{-1}$) By Depth',fontsize=12)\n",
    "ax.legend(frameon=True,fontsize=12)\n",
    "#fig.savefig('SaanichLog10ModelvsObsProductivity.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (6,6))\n",
    "with nc.Dataset('/ocean/ksuchy/MOAD/NEMO-forcing/grid/bathymetry_202108.nc') as grid:\n",
    "    viz_tools.plot_coastline(ax, grid, coords = 'map',isobath=.1,color='darkgrey')\n",
    "colors=('royalblue',\n",
    "'green',\n",
    "'orange',\n",
    "'mediumspringgreen',\n",
    "'black',\n",
    "'darkviolet',\n",
    " 'lightblue',\n",
    "'fuchsia',\n",
    "'firebrick','lime','darkgoldenrod','darkorange','deepskyblue','teal','darkgreen','darkblue','slateblue','purple')\n",
    "datreg=dict()\n",
    "for ind, iregion in enumerate(data.Station.unique()):\n",
    "    datreg[iregion] = data.loc[data.Station==iregion]\n",
    "    ax.plot(datreg[iregion]['Lon'], datreg[iregion]['Lat'],'o',\n",
    "            color = colors[ind], label=iregion,markersize=4)\n",
    "ax.set_ylim(47, 51)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "ax.legend(bbox_to_anchor=(1.1, 1),frameon=False,markerscale=3.)\n",
    "ax.set_xlim(-126, -121);\n",
    "ax.set_title('Observation Locations');\n",
    "#ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left',frameon=False,markerscale=3.,fontsize=11)\n",
    "ax.axis(\"off\")\n",
    "#fig.savefig('SalishSeaObservationLocations_noframe.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['dtUTC'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byRegion(ax,obsvar,modvar,lims):\n",
    "    SS=[]\n",
    "    for ind, iregion in enumerate(data.Station.unique()):\n",
    "        #ax.plot(datreg[iregion]['Lon'], datreg[iregion]['Lat'],'.',\n",
    "                #color = colors[ind], label=iregion)\n",
    "        SS0=et.varvarPlot(ax,datreg[iregion],obsvar,modvar,\n",
    "                          cols=(colors[ind],),lname=iregion)\n",
    "        SS.append(SS0)\n",
    "    l=ax.legend(handles=[ip[0][0] for ip in SS])\n",
    "    ax.set_xlabel('Log10 Observations (mg C m$^{-3}$ d$^{-1}$)+0.001')\n",
    "    ax.set_ylabel('Log10 Model (mg C m$^{-3}$ d$^{-1}$)+0.001')\n",
    "    ax.plot(lims,lims,'k-',alpha=.5)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect(1)\n",
    "    return SS,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Month']=[ii.month for ii in data['dtUTC']]\n",
    "DJF=data.loc[(data.Month==12)|(data.Month==1)|(data.Month==2)]\n",
    "MAM=data.loc[(data.Month==3)|(data.Month==4)|(data.Month==5)]\n",
    "JJA=data.loc[(data.Month==6)|(data.Month==7)|(data.Month==8)]\n",
    "SON=data.loc[(data.Month==9)|(data.Month==10)|(data.Month==11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bySeason(ax,obsvar,modvar,lims):\n",
    "    for axi in ax:\n",
    "        axi.plot(lims,lims,'k-')\n",
    "        axi.set_xlim(lims)\n",
    "        axi.set_ylim(lims)\n",
    "        axi.set_aspect(1)\n",
    "        axi.set_xlabel('Obs')\n",
    "        axi.set_ylabel('Model')\n",
    "    SS=et.varvarPlot(ax[0],DJF,obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[0].set_title('Winter')\n",
    "    SS=et.varvarPlot(ax[1],MAM,obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[1].set_title('Spring')\n",
    "    SS=et.varvarPlot(ax[2],JJA,obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[2].set_title('Summer')\n",
    "    SS=et.varvarPlot(ax[3],SON,obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[3].set_title('Autumn')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (5,4))     \n",
    "SS,l=byRegion(ax,'L10Productivity','L10mod_prod',(-3,3))\n",
    "ax.set_title('Z2 Productivity - By Region',fontsize=18)\n",
    "ax.legend(bbox_to_anchor=(1.1, 1.05),frameon=False,markerscale=2.5)\n",
    "#fig.savefig('SalishSeaDIMicroZoopEval_byregion_noLegend.jpg',bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize = (16,3.3))\n",
    "bySeason(ax,'L10Productivity','L10mod_prod',(-3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These groupings will be used to calculate statistics. The keys are labels and\n",
    "### the values are corresponding dataframe views\n",
    "statsubs=OrderedDict({\n",
    "                      'All':data,\n",
    "                      'Winter':DJF,\n",
    "                      'Spring':MAM,\n",
    "                      'Summer':JJA,\n",
    "                      'Autumn': SON,})\n",
    "for iregion in data.Station.unique():\n",
    "    statsubs[iregion]=datreg[iregion]\n",
    "statsubs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining variables needed for mesozooplankton evaluations\n",
    "obsvar4='L10Productivity'\n",
    "modvar4='L10mod_prod'\n",
    "year=2023 #how do I calculate for all years?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDict={year:dict()}\n",
    "statsDict[year]['MicroZ']=OrderedDict()\n",
    "for isub in statsubs:\n",
    "    print(isub)\n",
    "    statsDict[year]['MicroZ'][isub]=dict()\n",
    "    var=statsDict[year]['MicroZ'][isub]\n",
    "    var['N'],var['mmean'],var['omean'],var['Bias'],var['RMSE'],var['WSS']=et.stats(statsubs[isub].loc[:,[obsvar4]],\n",
    "                                                                     statsubs[isub].loc[:,[modvar4]])\n",
    "tbl,tdf=et.displayStats(statsDict[year]['MicroZ'],level='Subset',suborder=list(statsubs.keys()))\n",
    "tbl\n",
    "\n",
    "#tbl.to_excel(\"SalishSeaMicrozoopEvalStats.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zeroes = data[data['mod_prod'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
